<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>ai</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"></script>
    <script src="./lib/ndarray-browser-min.js"></script>
    <script src="./lib/image-loader.js"></script>
    <script src="./lib/imagenetClasses.js"></script>
    <style>
        video {
            width: 500px;
            height: 500px;
        }
        
        font {
            font-family: "微软雅黑";
        }
    </style>

</head>

<body>
    <h1>Resnet18</h1>
    <div>
        <video id="video" autoplay></video>
        <!-- <button id="snap">Snap Photo</button> -->
        <canvas id="canvas" hidden="false" width="750" height="560"></canvas>
    </div>
    <div>
        <div id="predictions"></div>
    </div>
    <script>
        //video
        if (navigator.mediaDevices === undefined) {
            navigator.mediaDevices = {};
        }

        // 一些浏览器部分支持 mediaDevices。我们不能直接给对象设置 getUserMedia
        // 因为这样可能会覆盖已有的属性。这里我们只会在没有getUserMedia属性的时候添加它。
        if (navigator.mediaDevices.getUserMedia === undefined) {
            navigator.mediaDevices.getUserMedia = function(constraints) {

                // 首先，如果有getUserMedia的话，就获得它
                var getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

                // 一些浏览器根本没实现它 - 那么就返回一个error到promise的reject来保持一个统一的接口
                if (!getUserMedia) {
                    return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
                }

                // 否则，为老的navigator.getUserMedia方法包裹一个Promise
                return new Promise(function(resolve, reject) {
                    getUserMedia.call(navigator, constraints, resolve, reject);
                });
            }
        }


        var video = document.getElementById('video');
        //var snap = document.getElementById('snap');
        var canvas = document.getElementById('canvas');
        var ctx = canvas.getContext('2d');
        var imageData;

        //後置攝像頭
        navigator.mediaDevices.getUserMedia({
                audio: false,
                video: {
                    facingMode: "environment"
                }
            })
            .then(function(stream) {
                // 旧的浏览器可能没有srcObject
                if ("srcObject" in video) {
                    video.srcObject = stream;
                } else {
                    // 防止在新的浏览器里使用它，应为它已经不再支持了
                    video.src = window.URL.createObjectURL(stream);
                }
                video.onloadedmetadata = function(e) {
                    video.play();
                };
            })
            .catch(function(err) {
                console.log(err.name + ": " + err.message);
            });

        //get video frame
        function getVideoFrame() {
            ctx.drawImage(video, 0, 0, 750, 560);
            imageData = ctx.getImageData(0, 0, 750, 560);
            //console.log("getVideoFrame");
        }

        //resnet
        const imageSize = 224;
        //create onnx inference with webgl
        const session = new onnx.InferenceSession({
            backendHint: 'webgl'
        });
        //load onnx model
        //session.loadModel("http://127.0.0.1:8080/resnet18.onnx");
        //session.loadModel("http://127.0.0.1:8080/ssd-mobilenet.onnx");
        session.loadModel("http://127.0.0.1:8080/yolo.onnx");
        //session.loadModel("http://127.0.0.1:8080/resnet50v2.onnx");

        async function runAI() {
            //const session = new onnx.InferenceSession({ backendHint: 'webgl' });
            //await session.loadModel("http://127.0.0.1:8080/resnet18.onnx");

            let dateStart = new Date();

            //preprocess img data
            const width = imageSize;
            const height = imageSize;
            const preprocessedData = preprocess(imageData.data, width, height);

            const inputTensor = new onnx.Tensor(preprocessedData, 'float32', [1, 3, width, height]);
            // Run model with Tensor inputs and get the result.
            const outputMap = await session.run([inputTensor]);
            const outputData = outputMap.values().next().value.data;

            let dateEnd = new Date();
            // Render the output result in html.
            console.log(outputData);
            findAndPrintMax(outputData, dateEnd.getTime() - dateStart.getTime());
            //console.log("runAI");
        }

        function preprocess(data, width, height) {
            const dataFromImage = ndarray(new Float32Array(data), [width, height, 4]);
            const dataProcessed = ndarray(new Float32Array(width * height * 3), [1, 3, height, width]);

            // Normalize 0-255 to (-1)-1
            ndarray.ops.divseq(dataFromImage, 128.0);
            ndarray.ops.subseq(dataFromImage, 1.0);

            // Realign imageData from [224*224*4] to the correct dimension [1*3*224*224].
            ndarray.ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 2));
            ndarray.ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 1));
            ndarray.ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 0));

            return dataProcessed.data;
        }

        /**
         * Render output to Html.
         */
        function findAndPrintMax(data, time) {
            let maxValue = 0.0;
            let maxIndex = 0.0;

            predictions = document.getElementById('predictions');
            for (let i = 0; i < data.length; i++) {
                if (data[i] > maxValue) {
                    maxValue = data[i];
                    maxIndex = i;
                }
            }
            predictions.innerHTML = '<p><font size="32" color="black">' +
                imagenetClasses[maxIndex] + ' : ' +
                (0 | data[maxIndex] * 100) +
                "% Time : " + time + "ms"; +
            '</font></p>'
        }

        //timer
        setInterval("getVideoFrame()", 100);
        setInterval("runAI()", 1000);
    </script>
</body>

</html>